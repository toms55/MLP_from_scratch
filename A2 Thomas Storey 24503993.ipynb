{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMH5T+gifbnfLUVWxTXxtY8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tg3AHUS-zXl0","executionInfo":{"status":"ok","timestamp":1759736806842,"user_tz":-660,"elapsed":920,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"71d1d35d-c400-4c89-c1a2-c69af98a8c16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MLP_from_scratch'...\n","remote: Enumerating objects: 523, done.\u001b[K\n","remote: Counting objects: 100% (523/523), done.\u001b[K\n","remote: Compressing objects: 100% (337/337), done.\u001b[K\n","remote: Total 523 (delta 241), reused 448 (delta 166), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (523/523), 2.38 MiB | 14.66 MiB/s, done.\n","Resolving deltas: 100% (241/241), done.\n"]}],"source":["!git clone https://github.com/toms55/MLP_from_scratch.git"]},{"cell_type":"code","source":["!apt-get update"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmC6f-HSzvkw","executionInfo":{"status":"ok","timestamp":1759736814592,"user_tz":-660,"elapsed":7746,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"4de48119-b21f-4a3d-87f6-3707b0ccfdab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Connecting to security.ubuntu.com (185.125.190.39)] [Connecting to cloud.r-\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:3 https://cli.github.com/packages stable InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,065 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,738 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,580 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,808 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,322 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n","Fetched 20.0 MB in 5s (3,837 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}]},{"cell_type":"code","source":["!apt-get install -y gcc cmake gdb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OL7lvAbo0NZW","executionInfo":{"status":"ok","timestamp":1759736826339,"user_tz":-660,"elapsed":11740,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"e7ac42b1-816b-4d70-f047-9040df03fcb1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","gcc is already the newest version (4:11.2.0-1ubuntu1).\n","gcc set to manually installed.\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","The following additional packages will be installed:\n","  libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n","  libsource-highlight-common libsource-highlight4v5\n","Suggested packages:\n","  gdb-doc gdbserver\n","The following NEW packages will be installed:\n","  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n","  libsource-highlight-common libsource-highlight4v5\n","0 upgraded, 8 newly installed, 0 to remove and 40 not upgraded.\n","Need to get 18.3 MB of archives.\n","After this operation, 32.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod-common all 0.186-1ubuntu0.1 [7,996 B]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod1 amd64 0.186-1ubuntu0.1 [12.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.11 [13.9 MB]\n","Fetched 18.3 MB in 1s (31.2 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package libdebuginfod-common.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../0-libdebuginfod-common_0.186-1ubuntu0.1_all.deb ...\n","Unpacking libdebuginfod-common (0.186-1ubuntu0.1) ...\n","Selecting previously unselected package libbabeltrace1:amd64.\n","Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n","Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Selecting previously unselected package libdebuginfod1:amd64.\n","Preparing to unpack .../2-libdebuginfod1_0.186-1ubuntu0.1_amd64.deb ...\n","Unpacking libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n","Selecting previously unselected package libipt2.\n","Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n","Unpacking libipt2 (2.0.5-1) ...\n","Selecting previously unselected package libsource-highlight-common.\n","Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n","Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n","Selecting previously unselected package libsource-highlight4v5.\n","Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n","Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Selecting previously unselected package gdb.\n","Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n","Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n","Selecting previously unselected package libc6-dbg:amd64.\n","Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.11_amd64.deb ...\n","Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.11) ...\n","Setting up libdebuginfod-common (0.186-1ubuntu0.1) ...\n","\n","Creating config file /etc/profile.d/debuginfod.sh with new version\n","\n","Creating config file /etc/profile.d/debuginfod.csh with new version\n","Setting up libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n","Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n","Setting up libc6-dbg:amd64 (2.35-0ubuntu3.11) ...\n","Setting up libipt2 (2.0.5-1) ...\n","Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n"]}]},{"cell_type":"code","source":["!pip install numpy pandas scipy matplotlib scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXjoVyGr0Q8s","executionInfo":{"status":"ok","timestamp":1759736834096,"user_tz":-660,"elapsed":7749,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"f409edef-b035-48fe-e588-e302f12ce661"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"code","source":["%cd /content/MLP_from_scratch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vQLK7Ft0UFB","executionInfo":{"status":"ok","timestamp":1759736834118,"user_tz":-660,"elapsed":8,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"e657a041-1a90-407b-bb9d-5e1a7c44b406"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MLP_from_scratch\n"]}]},{"cell_type":"markdown","source":["Compile the C Code"],"metadata":{"id":"ncciChudFBAq"}},{"cell_type":"code","source":["!make clean\n","!make all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCSB2kKf0nzZ","executionInfo":{"status":"ok","timestamp":1759736835143,"user_tz":-660,"elapsed":1011,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"d4afe506-e38c-454b-9f44-c83fb0d7b657"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["rm -rf build c_src/src/*.o\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/activation.o c_src/src/activation.c\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/loss.o c_src/src/loss.c\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/matrix.o c_src/src/matrix.c\n","mkdir -p build\n","gcc -shared -lm -o build/libmlp.so c_src/src/activation.o c_src/src/loss.o c_src/src/matrix.o\n"]}]},{"cell_type":"code","source":["!python3 python/run.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0387OYh1Ex5","executionInfo":{"status":"ok","timestamp":1759736886847,"user_tz":-660,"elapsed":51689,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"bc46aa6d-06a6-4979-b5d3-d4983b21d155"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","MLP IMPLEMENTATION BENCHMARK\n","================================================================================\n","\n","Loading California Housing Dataset...\n","Scaling features...\n","\n","Dataset Info:\n","Training samples: 18576\n","Test samples: 2064\n","Features: 8\n","Epochs: 500\n","\n","============================================================\n","BENCHMARKING CUSTOM MLP\n","============================================================\n","Training epoch 0\n","\n","This epoch's loss is 2.868645\n","Training epoch 1\n","\n","This epoch's loss is 2.790456\n","Training epoch 2\n","\n","This epoch's loss is 2.718115\n","Training epoch 3\n","\n","This epoch's loss is 2.651047\n","Training epoch 4\n","\n","This epoch's loss is 2.588733\n","Training epoch 5\n","\n","This epoch's loss is 2.530639\n","Training epoch 6\n","\n","This epoch's loss is 2.476347\n","Training epoch 7\n","\n","This epoch's loss is 2.425517\n","Training epoch 8\n","\n","This epoch's loss is 2.377834\n","Training epoch 9\n","\n","This epoch's loss is 2.332970\n","Training epoch 10\n","\n","This epoch's loss is 2.290709\n","Training epoch 11\n","\n","This epoch's loss is 2.250804\n","Training epoch 12\n","\n","This epoch's loss is 2.213039\n","Training epoch 13\n","\n","This epoch's loss is 2.177259\n","Training epoch 14\n","\n","This epoch's loss is 2.143223\n","Training epoch 15\n","\n","This epoch's loss is 2.110577\n","Training epoch 16\n","\n","This epoch's loss is 2.079401\n","Training epoch 17\n","\n","This epoch's loss is 2.049602\n","Training epoch 18\n","\n","This epoch's loss is 2.021106\n","Training epoch 19\n","\n","This epoch's loss is 1.993807\n","Training epoch 20\n","\n","This epoch's loss is 1.967603\n","Training epoch 21\n","\n","This epoch's loss is 1.942411\n","Training epoch 22\n","\n","This epoch's loss is 1.918154\n","Training epoch 23\n","\n","This epoch's loss is 1.894769\n","Training epoch 24\n","\n","This epoch's loss is 1.872188\n","Training epoch 25\n","\n","This epoch's loss is 1.850345\n","Training epoch 26\n","\n","This epoch's loss is 1.829176\n","Training epoch 27\n","\n","This epoch's loss is 1.808672\n","Training epoch 28\n","\n","This epoch's loss is 1.788786\n","Training epoch 29\n","\n","This epoch's loss is 1.769488\n","Training epoch 30\n","\n","This epoch's loss is 1.750740\n","Training epoch 31\n","\n","This epoch's loss is 1.732530\n","Training epoch 32\n","\n","This epoch's loss is 1.714823\n","Training epoch 33\n","\n","This epoch's loss is 1.697600\n","Training epoch 34\n","\n","This epoch's loss is 1.680837\n","Training epoch 35\n","\n","This epoch's loss is 1.664513\n","Training epoch 36\n","\n","This epoch's loss is 1.648610\n","Training epoch 37\n","\n","This epoch's loss is 1.633122\n","Training epoch 38\n","\n","This epoch's loss is 1.618033\n","Training epoch 39\n","\n","This epoch's loss is 1.603312\n","Training epoch 40\n","\n","This epoch's loss is 1.588941\n","Training epoch 41\n","\n","This epoch's loss is 1.574924\n","Training epoch 42\n","\n","This epoch's loss is 1.561243\n","Training epoch 43\n","\n","This epoch's loss is 1.547889\n","Training epoch 44\n","\n","This epoch's loss is 1.534862\n","Training epoch 45\n","\n","This epoch's loss is 1.522152\n","Training epoch 46\n","\n","This epoch's loss is 1.509739\n","Training epoch 47\n","\n","This epoch's loss is 1.497613\n","Training epoch 48\n","\n","This epoch's loss is 1.485766\n","Training epoch 49\n","\n","This epoch's loss is 1.474190\n","Training epoch 50\n","\n","This epoch's loss is 1.462875\n","Training epoch 51\n","\n","This epoch's loss is 1.451833\n","Training epoch 52\n","\n","This epoch's loss is 1.441038\n","Training epoch 53\n","\n","This epoch's loss is 1.430487\n","Training epoch 54\n","\n","This epoch's loss is 1.420188\n","Training epoch 55\n","\n","This epoch's loss is 1.410124\n","Training epoch 56\n","\n","This epoch's loss is 1.400291\n","Training epoch 57\n","\n","This epoch's loss is 1.390679\n","Training epoch 58\n","\n","This epoch's loss is 1.381274\n","Training epoch 59\n","\n","This epoch's loss is 1.372065\n","Training epoch 60\n","\n","This epoch's loss is 1.363051\n","Training epoch 61\n","\n","This epoch's loss is 1.354232\n","Training epoch 62\n","\n","This epoch's loss is 1.345593\n","Training epoch 63\n","\n","This epoch's loss is 1.337144\n","Training epoch 64\n","\n","This epoch's loss is 1.328873\n","Training epoch 65\n","\n","This epoch's loss is 1.320792\n","Training epoch 66\n","\n","This epoch's loss is 1.312880\n","Training epoch 67\n","\n","This epoch's loss is 1.305137\n","Training epoch 68\n","\n","This epoch's loss is 1.297565\n","Training epoch 69\n","\n","This epoch's loss is 1.290189\n","Training epoch 70\n","\n","This epoch's loss is 1.282984\n","Training epoch 71\n","\n","This epoch's loss is 1.275937\n","Training epoch 72\n","\n","This epoch's loss is 1.269063\n","Training epoch 73\n","\n","This epoch's loss is 1.262358\n","Training epoch 74\n","\n","This epoch's loss is 1.255805\n","Training epoch 75\n","\n","This epoch's loss is 1.249415\n","Training epoch 76\n","\n","This epoch's loss is 1.243173\n","Training epoch 77\n","\n","This epoch's loss is 1.237094\n","Training epoch 78\n","\n","This epoch's loss is 1.231259\n","Training epoch 79\n","\n","This epoch's loss is 1.225578\n","Training epoch 80\n","\n","This epoch's loss is 1.220022\n","Training epoch 81\n","\n","This epoch's loss is 1.214584\n","Training epoch 82\n","\n","This epoch's loss is 1.209387\n","Training epoch 83\n","\n","This epoch's loss is 1.204591\n","Training epoch 84\n","\n","This epoch's loss is 1.199874\n","Training epoch 85\n","\n","This epoch's loss is 1.195234\n","Training epoch 86\n","\n","This epoch's loss is 1.190668\n","Training epoch 87\n","\n","This epoch's loss is 1.186229\n","Training epoch 88\n","\n","This epoch's loss is 1.181920\n","Training epoch 89\n","\n","This epoch's loss is 1.177684\n","Training epoch 90\n","\n","This epoch's loss is 1.173527\n","Training epoch 91\n","\n","This epoch's loss is 1.169460\n","Training epoch 92\n","\n","This epoch's loss is 1.165468\n","Training epoch 93\n","\n","This epoch's loss is 1.161549\n","Training epoch 94\n","\n","This epoch's loss is 1.157694\n","Training epoch 95\n","\n","This epoch's loss is 1.153936\n","Training epoch 96\n","\n","This epoch's loss is 1.150251\n","Training epoch 97\n","\n","This epoch's loss is 1.146644\n","Training epoch 98\n","\n","This epoch's loss is 1.143094\n","Training epoch 99\n","\n","This epoch's loss is 1.139605\n","Training epoch 100\n","\n","This epoch's loss is 1.136177\n","Training epoch 101\n","\n","This epoch's loss is 1.132808\n","Training epoch 102\n","\n","This epoch's loss is 1.129494\n","Training epoch 103\n","\n","This epoch's loss is 1.126242\n","Training epoch 104\n","\n","This epoch's loss is 1.123072\n","Training epoch 105\n","\n","This epoch's loss is 1.119956\n","Training epoch 106\n","\n","This epoch's loss is 1.116922\n","Training epoch 107\n","\n","This epoch's loss is 1.114011\n","Training epoch 108\n","\n","This epoch's loss is 1.111146\n","Training epoch 109\n","\n","This epoch's loss is 1.108327\n","Training epoch 110\n","\n","This epoch's loss is 1.105549\n","Training epoch 111\n","\n","This epoch's loss is 1.102815\n","Training epoch 112\n","\n","This epoch's loss is 1.100126\n","Training epoch 113\n","\n","This epoch's loss is 1.097476\n","Training epoch 114\n","\n","This epoch's loss is 1.094870\n","Training epoch 115\n","\n","This epoch's loss is 1.092303\n","Training epoch 116\n","\n","This epoch's loss is 1.089777\n","Training epoch 117\n","\n","This epoch's loss is 1.087298\n","Training epoch 118\n","\n","This epoch's loss is 1.084856\n","Training epoch 119\n","\n","This epoch's loss is 1.082450\n","Training epoch 120\n","\n","This epoch's loss is 1.080080\n","Training epoch 121\n","\n","This epoch's loss is 1.077748\n","Training epoch 122\n","\n","This epoch's loss is 1.075455\n","Training epoch 123\n","\n","This epoch's loss is 1.073203\n","Training epoch 124\n","\n","This epoch's loss is 1.070988\n","Training epoch 125\n","\n","This epoch's loss is 1.068813\n","Training epoch 126\n","\n","This epoch's loss is 1.066674\n","Training epoch 127\n","\n","This epoch's loss is 1.064566\n","Training epoch 128\n","\n","This epoch's loss is 1.062487\n","Training epoch 129\n","\n","This epoch's loss is 1.060438\n","Training epoch 130\n","\n","This epoch's loss is 1.058418\n","Training epoch 131\n","\n","This epoch's loss is 1.056426\n","Training epoch 132\n","\n","This epoch's loss is 1.054461\n","Training epoch 133\n","\n","This epoch's loss is 1.052522\n","Training epoch 134\n","\n","This epoch's loss is 1.050609\n","Training epoch 135\n","\n","This epoch's loss is 1.048723\n","Training epoch 136\n","\n","This epoch's loss is 1.046867\n","Training epoch 137\n","\n","This epoch's loss is 1.045044\n","Training epoch 138\n","\n","This epoch's loss is 1.043245\n","Training epoch 139\n","\n","This epoch's loss is 1.041469\n","Training epoch 140\n","\n","This epoch's loss is 1.039717\n","Training epoch 141\n","\n","This epoch's loss is 1.037987\n","Training epoch 142\n","\n","This epoch's loss is 1.036278\n","Training epoch 143\n","\n","This epoch's loss is 1.034591\n","Training epoch 144\n","\n","This epoch's loss is 1.032924\n","Training epoch 145\n","\n","This epoch's loss is 1.031279\n","Training epoch 146\n","\n","This epoch's loss is 1.029655\n","Training epoch 147\n","\n","This epoch's loss is 1.028052\n","Training epoch 148\n","\n","This epoch's loss is 1.026466\n","Training epoch 149\n","\n","This epoch's loss is 1.024901\n","Training epoch 150\n","\n","This epoch's loss is 1.023354\n","Training epoch 151\n","\n","This epoch's loss is 1.021826\n","Training epoch 152\n","\n","This epoch's loss is 1.020316\n","Training epoch 153\n","\n","This epoch's loss is 1.018824\n","Training epoch 154\n","\n","This epoch's loss is 1.017351\n","Training epoch 155\n","\n","This epoch's loss is 1.015893\n","Training epoch 156\n","\n","This epoch's loss is 1.014452\n","Training epoch 157\n","\n","This epoch's loss is 1.013028\n","Training epoch 158\n","\n","This epoch's loss is 1.011621\n","Training epoch 159\n","\n","This epoch's loss is 1.010230\n","Training epoch 160\n","\n","This epoch's loss is 1.008856\n","Training epoch 161\n","\n","This epoch's loss is 1.007497\n","Training epoch 162\n","\n","This epoch's loss is 1.006154\n","Training epoch 163\n","\n","This epoch's loss is 1.004826\n","Training epoch 164\n","\n","This epoch's loss is 1.003513\n","Training epoch 165\n","\n","This epoch's loss is 1.002214\n","Training epoch 166\n","\n","This epoch's loss is 1.000928\n","Training epoch 167\n","\n","This epoch's loss is 0.999657\n","Training epoch 168\n","\n","This epoch's loss is 0.998399\n","Training epoch 169\n","\n","This epoch's loss is 0.997155\n","Training epoch 170\n","\n","This epoch's loss is 0.995922\n","Training epoch 171\n","\n","This epoch's loss is 0.994701\n","Training epoch 172\n","\n","This epoch's loss is 0.993493\n","Training epoch 173\n","\n","This epoch's loss is 0.992296\n","Training epoch 174\n","\n","This epoch's loss is 0.991109\n","Training epoch 175\n","\n","This epoch's loss is 0.989934\n","Training epoch 176\n","\n","This epoch's loss is 0.988769\n","Training epoch 177\n","\n","This epoch's loss is 0.987615\n","Training epoch 178\n","\n","This epoch's loss is 0.986471\n","Training epoch 179\n","\n","This epoch's loss is 0.985337\n","Training epoch 180\n","\n","This epoch's loss is 0.984213\n","Training epoch 181\n","\n","This epoch's loss is 0.983099\n","Training epoch 182\n","\n","This epoch's loss is 0.981994\n","Training epoch 183\n","\n","This epoch's loss is 0.980899\n","Training epoch 184\n","\n","This epoch's loss is 0.979813\n","Training epoch 185\n","\n","This epoch's loss is 0.978741\n","Training epoch 186\n","\n","This epoch's loss is 0.977681\n","Training epoch 187\n","\n","This epoch's loss is 0.976630\n","Training epoch 188\n","\n","This epoch's loss is 0.975588\n","Training epoch 189\n","\n","This epoch's loss is 0.974555\n","Training epoch 190\n","\n","This epoch's loss is 0.973531\n","Training epoch 191\n","\n","This epoch's loss is 0.972515\n","Training epoch 192\n","\n","This epoch's loss is 0.971507\n","Training epoch 193\n","\n","This epoch's loss is 0.970507\n","Training epoch 194\n","\n","This epoch's loss is 0.969514\n","Training epoch 195\n","\n","This epoch's loss is 0.968529\n","Training epoch 196\n","\n","This epoch's loss is 0.967551\n","Training epoch 197\n","\n","This epoch's loss is 0.966581\n","Training epoch 198\n","\n","This epoch's loss is 0.965618\n","Training epoch 199\n","\n","This epoch's loss is 0.964664\n","Training epoch 200\n","\n","This epoch's loss is 0.963717\n","Training epoch 201\n","\n","This epoch's loss is 0.962777\n","Training epoch 202\n","\n","This epoch's loss is 0.961842\n","Training epoch 203\n","\n","This epoch's loss is 0.960915\n","Training epoch 204\n","\n","This epoch's loss is 0.959993\n","Training epoch 205\n","\n","This epoch's loss is 0.959078\n","Training epoch 206\n","\n","This epoch's loss is 0.958169\n","Training epoch 207\n","\n","This epoch's loss is 0.957265\n","Training epoch 208\n","\n","This epoch's loss is 0.956368\n","Training epoch 209\n","\n","This epoch's loss is 0.955477\n","Training epoch 210\n","\n","This epoch's loss is 0.954592\n","Training epoch 211\n","\n","This epoch's loss is 0.953713\n","Training epoch 212\n","\n","This epoch's loss is 0.952840\n","Training epoch 213\n","\n","This epoch's loss is 0.951972\n","Training epoch 214\n","\n","This epoch's loss is 0.951111\n","Training epoch 215\n","\n","This epoch's loss is 0.950254\n","Training epoch 216\n","\n","This epoch's loss is 0.949404\n","Training epoch 217\n","\n","This epoch's loss is 0.948559\n","Training epoch 218\n","\n","This epoch's loss is 0.947720\n","Training epoch 219\n","\n","This epoch's loss is 0.946885\n","Training epoch 220\n","\n","This epoch's loss is 0.946055\n","Training epoch 221\n","\n","This epoch's loss is 0.945230\n","Training epoch 222\n","\n","This epoch's loss is 0.944410\n","Training epoch 223\n","\n","This epoch's loss is 0.943595\n","Training epoch 224\n","\n","This epoch's loss is 0.942784\n","Training epoch 225\n","\n","This epoch's loss is 0.941978\n","Training epoch 226\n","\n","This epoch's loss is 0.941176\n","Training epoch 227\n","\n","This epoch's loss is 0.940379\n","Training epoch 228\n","\n","This epoch's loss is 0.939586\n","Training epoch 229\n","\n","This epoch's loss is 0.938797\n","Training epoch 230\n","\n","This epoch's loss is 0.938014\n","Training epoch 231\n","\n","This epoch's loss is 0.937234\n","Training epoch 232\n","\n","This epoch's loss is 0.936460\n","Training epoch 233\n","\n","This epoch's loss is 0.935689\n","Training epoch 234\n","\n","This epoch's loss is 0.934923\n","Training epoch 235\n","\n","This epoch's loss is 0.934161\n","Training epoch 236\n","\n","This epoch's loss is 0.933402\n","Training epoch 237\n","\n","This epoch's loss is 0.932647\n","Training epoch 238\n","\n","This epoch's loss is 0.931896\n","Training epoch 239\n","\n","This epoch's loss is 0.931147\n","Training epoch 240\n","\n","This epoch's loss is 0.930402\n","Training epoch 241\n","\n","This epoch's loss is 0.929662\n","Training epoch 242\n","\n","This epoch's loss is 0.928925\n","Training epoch 243\n","\n","This epoch's loss is 0.928190\n","Training epoch 244\n","\n","This epoch's loss is 0.927460\n","Training epoch 245\n","\n","This epoch's loss is 0.926733\n","Training epoch 246\n","\n","This epoch's loss is 0.926010\n","Training epoch 247\n","\n","This epoch's loss is 0.925291\n","Training epoch 248\n","\n","This epoch's loss is 0.924575\n","Training epoch 249\n","\n","This epoch's loss is 0.923862\n","Training epoch 250\n","\n","This epoch's loss is 0.923153\n","Training epoch 251\n","\n","This epoch's loss is 0.922447\n","Training epoch 252\n","\n","This epoch's loss is 0.921744\n","Training epoch 253\n","\n","This epoch's loss is 0.921043\n","Training epoch 254\n","\n","This epoch's loss is 0.920347\n","Training epoch 255\n","\n","This epoch's loss is 0.919653\n","Training epoch 256\n","\n","This epoch's loss is 0.918964\n","Training epoch 257\n","\n","This epoch's loss is 0.918278\n","Training epoch 258\n","\n","This epoch's loss is 0.917595\n","Training epoch 259\n","\n","This epoch's loss is 0.916915\n","Training epoch 260\n","\n","This epoch's loss is 0.916238\n","Training epoch 261\n","\n","This epoch's loss is 0.915564\n","Training epoch 262\n","\n","This epoch's loss is 0.914892\n","Training epoch 263\n","\n","This epoch's loss is 0.914223\n","Training epoch 264\n","\n","This epoch's loss is 0.913556\n","Training epoch 265\n","\n","This epoch's loss is 0.912893\n","Training epoch 266\n","\n","This epoch's loss is 0.912233\n","Training epoch 267\n","\n","This epoch's loss is 0.911575\n","Training epoch 268\n","\n","This epoch's loss is 0.910920\n","Training epoch 269\n","\n","This epoch's loss is 0.910268\n","Training epoch 270\n","\n","This epoch's loss is 0.909619\n","Training epoch 271\n","\n","This epoch's loss is 0.908972\n","Training epoch 272\n","\n","This epoch's loss is 0.908329\n","Training epoch 273\n","\n","This epoch's loss is 0.907688\n","Training epoch 274\n","\n","This epoch's loss is 0.907050\n","Training epoch 275\n","\n","This epoch's loss is 0.906414\n","Training epoch 276\n","\n","This epoch's loss is 0.905780\n","Training epoch 277\n","\n","This epoch's loss is 0.905150\n","Training epoch 278\n","\n","This epoch's loss is 0.904521\n","Training epoch 279\n","\n","This epoch's loss is 0.903894\n","Training epoch 280\n","\n","This epoch's loss is 0.903269\n","Training epoch 281\n","\n","This epoch's loss is 0.902647\n","Training epoch 282\n","\n","This epoch's loss is 0.902027\n","Training epoch 283\n","\n","This epoch's loss is 0.901410\n","Training epoch 284\n","\n","This epoch's loss is 0.900794\n","Training epoch 285\n","\n","This epoch's loss is 0.900181\n","Training epoch 286\n","\n","This epoch's loss is 0.899570\n","Training epoch 287\n","\n","This epoch's loss is 0.898962\n","Training epoch 288\n","\n","This epoch's loss is 0.898355\n","Training epoch 289\n","\n","This epoch's loss is 0.897750\n","Training epoch 290\n","\n","This epoch's loss is 0.897147\n","Training epoch 291\n","\n","This epoch's loss is 0.896546\n","Training epoch 292\n","\n","This epoch's loss is 0.895947\n","Training epoch 293\n","\n","This epoch's loss is 0.895350\n","Training epoch 294\n","\n","This epoch's loss is 0.894756\n","Training epoch 295\n","\n","This epoch's loss is 0.894164\n","Training epoch 296\n","\n","This epoch's loss is 0.893574\n","Training epoch 297\n","\n","This epoch's loss is 0.892985\n","Training epoch 298\n","\n","This epoch's loss is 0.892398\n","Training epoch 299\n","\n","This epoch's loss is 0.891814\n","Training epoch 300\n","\n","This epoch's loss is 0.891232\n","Training epoch 301\n","\n","This epoch's loss is 0.890652\n","Training epoch 302\n","\n","This epoch's loss is 0.890074\n","Training epoch 303\n","\n","This epoch's loss is 0.889499\n","Training epoch 304\n","\n","This epoch's loss is 0.888925\n","Training epoch 305\n","\n","This epoch's loss is 0.888353\n","Training epoch 306\n","\n","This epoch's loss is 0.887782\n","Training epoch 307\n","\n","This epoch's loss is 0.887214\n","Training epoch 308\n","\n","This epoch's loss is 0.886648\n","Training epoch 309\n","\n","This epoch's loss is 0.886083\n","Training epoch 310\n","\n","This epoch's loss is 0.885520\n","Training epoch 311\n","\n","This epoch's loss is 0.884959\n","Training epoch 312\n","\n","This epoch's loss is 0.884401\n","Training epoch 313\n","\n","This epoch's loss is 0.883844\n","Training epoch 314\n","\n","This epoch's loss is 0.883288\n","Training epoch 315\n","\n","This epoch's loss is 0.882735\n","Training epoch 316\n","\n","This epoch's loss is 0.882184\n","Training epoch 317\n","\n","This epoch's loss is 0.881634\n","Training epoch 318\n","\n","This epoch's loss is 0.881086\n","Training epoch 319\n","\n","This epoch's loss is 0.880541\n","Training epoch 320\n","\n","This epoch's loss is 0.879996\n","Training epoch 321\n","\n","This epoch's loss is 0.879454\n","Training epoch 322\n","\n","This epoch's loss is 0.878914\n","Training epoch 323\n","\n","This epoch's loss is 0.878375\n","Training epoch 324\n","\n","This epoch's loss is 0.877838\n","Training epoch 325\n","\n","This epoch's loss is 0.877302\n","Training epoch 326\n","\n","This epoch's loss is 0.876768\n","Training epoch 327\n","\n","This epoch's loss is 0.876235\n","Training epoch 328\n","\n","This epoch's loss is 0.875704\n","Training epoch 329\n","\n","This epoch's loss is 0.875174\n","Training epoch 330\n","\n","This epoch's loss is 0.874646\n","Training epoch 331\n","\n","This epoch's loss is 0.874120\n","Training epoch 332\n","\n","This epoch's loss is 0.873595\n","Training epoch 333\n","\n","This epoch's loss is 0.873072\n","Training epoch 334\n","\n","This epoch's loss is 0.872551\n","Training epoch 335\n","\n","This epoch's loss is 0.872031\n","Training epoch 336\n","\n","This epoch's loss is 0.871512\n","Training epoch 337\n","\n","This epoch's loss is 0.870995\n","Training epoch 338\n","\n","This epoch's loss is 0.870480\n","Training epoch 339\n","\n","This epoch's loss is 0.869966\n","Training epoch 340\n","\n","This epoch's loss is 0.869453\n","Training epoch 341\n","\n","This epoch's loss is 0.868942\n","Training epoch 342\n","\n","This epoch's loss is 0.868433\n","Training epoch 343\n","\n","This epoch's loss is 0.867925\n","Training epoch 344\n","\n","This epoch's loss is 0.867419\n","Training epoch 345\n","\n","This epoch's loss is 0.866914\n","Training epoch 346\n","\n","This epoch's loss is 0.866410\n","Training epoch 347\n","\n","This epoch's loss is 0.865908\n","Training epoch 348\n","\n","This epoch's loss is 0.865407\n","Training epoch 349\n","\n","This epoch's loss is 0.864908\n","Training epoch 350\n","\n","This epoch's loss is 0.864409\n","Training epoch 351\n","\n","This epoch's loss is 0.863912\n","Training epoch 352\n","\n","This epoch's loss is 0.863417\n","Training epoch 353\n","\n","This epoch's loss is 0.862923\n","Training epoch 354\n","\n","This epoch's loss is 0.862431\n","Training epoch 355\n","\n","This epoch's loss is 0.861940\n","Training epoch 356\n","\n","This epoch's loss is 0.861450\n","Training epoch 357\n","\n","This epoch's loss is 0.860962\n","Training epoch 358\n","\n","This epoch's loss is 0.860475\n","Training epoch 359\n","\n","This epoch's loss is 0.859989\n","Training epoch 360\n","\n","This epoch's loss is 0.859505\n","Training epoch 361\n","\n","This epoch's loss is 0.859022\n","Training epoch 362\n","\n","This epoch's loss is 0.858540\n","Training epoch 363\n","\n","This epoch's loss is 0.858060\n","Training epoch 364\n","\n","This epoch's loss is 0.857581\n","Training epoch 365\n","\n","This epoch's loss is 0.857103\n","Training epoch 366\n","\n","This epoch's loss is 0.856627\n","Training epoch 367\n","\n","This epoch's loss is 0.856152\n","Training epoch 368\n","\n","This epoch's loss is 0.855678\n","Training epoch 369\n","\n","This epoch's loss is 0.855206\n","Training epoch 370\n","\n","This epoch's loss is 0.854735\n","Training epoch 371\n","\n","This epoch's loss is 0.854266\n","Training epoch 372\n","\n","This epoch's loss is 0.853798\n","Training epoch 373\n","\n","This epoch's loss is 0.853331\n","Training epoch 374\n","\n","This epoch's loss is 0.852865\n","Training epoch 375\n","\n","This epoch's loss is 0.852400\n","Training epoch 376\n","\n","This epoch's loss is 0.851936\n","Training epoch 377\n","\n","This epoch's loss is 0.851474\n","Training epoch 378\n","\n","This epoch's loss is 0.851014\n","Training epoch 379\n","\n","This epoch's loss is 0.850554\n","Training epoch 380\n","\n","This epoch's loss is 0.850096\n","Training epoch 381\n","\n","This epoch's loss is 0.849638\n","Training epoch 382\n","\n","This epoch's loss is 0.849181\n","Training epoch 383\n","\n","This epoch's loss is 0.848726\n","Training epoch 384\n","\n","This epoch's loss is 0.848273\n","Training epoch 385\n","\n","This epoch's loss is 0.847821\n","Training epoch 386\n","\n","This epoch's loss is 0.847369\n","Training epoch 387\n","\n","This epoch's loss is 0.846919\n","Training epoch 388\n","\n","This epoch's loss is 0.846470\n","Training epoch 389\n","\n","This epoch's loss is 0.846022\n","Training epoch 390\n","\n","This epoch's loss is 0.845575\n","Training epoch 391\n","\n","This epoch's loss is 0.845129\n","Training epoch 392\n","\n","This epoch's loss is 0.844685\n","Training epoch 393\n","\n","This epoch's loss is 0.844241\n","Training epoch 394\n","\n","This epoch's loss is 0.843799\n","Training epoch 395\n","\n","This epoch's loss is 0.843357\n","Training epoch 396\n","\n","This epoch's loss is 0.842917\n","Training epoch 397\n","\n","This epoch's loss is 0.842476\n","Training epoch 398\n","\n","This epoch's loss is 0.842037\n","Training epoch 399\n","\n","This epoch's loss is 0.841600\n","Training epoch 400\n","\n","This epoch's loss is 0.841163\n","Training epoch 401\n","\n","This epoch's loss is 0.840727\n","Training epoch 402\n","\n","This epoch's loss is 0.840293\n","Training epoch 403\n","\n","This epoch's loss is 0.839860\n","Training epoch 404\n","\n","This epoch's loss is 0.839428\n","Training epoch 405\n","\n","This epoch's loss is 0.838997\n","Training epoch 406\n","\n","This epoch's loss is 0.838568\n","Training epoch 407\n","\n","This epoch's loss is 0.838139\n","Training epoch 408\n","\n","This epoch's loss is 0.837712\n","Training epoch 409\n","\n","This epoch's loss is 0.837286\n","Training epoch 410\n","\n","This epoch's loss is 0.836861\n","Training epoch 411\n","\n","This epoch's loss is 0.836437\n","Training epoch 412\n","\n","This epoch's loss is 0.836015\n","Training epoch 413\n","\n","This epoch's loss is 0.835593\n","Training epoch 414\n","\n","This epoch's loss is 0.835173\n","Training epoch 415\n","\n","This epoch's loss is 0.834754\n","Training epoch 416\n","\n","This epoch's loss is 0.834336\n","Training epoch 417\n","\n","This epoch's loss is 0.833919\n","Training epoch 418\n","\n","This epoch's loss is 0.833503\n","Training epoch 419\n","\n","This epoch's loss is 0.833089\n","Training epoch 420\n","\n","This epoch's loss is 0.832675\n","Training epoch 421\n","\n","This epoch's loss is 0.832262\n","Training epoch 422\n","\n","This epoch's loss is 0.831844\n","Training epoch 423\n","\n","This epoch's loss is 0.831427\n","Training epoch 424\n","\n","This epoch's loss is 0.831011\n","Training epoch 425\n","\n","This epoch's loss is 0.830596\n","Training epoch 426\n","\n","This epoch's loss is 0.830183\n","Training epoch 427\n","\n","This epoch's loss is 0.829770\n","Training epoch 428\n","\n","This epoch's loss is 0.829358\n","Training epoch 429\n","\n","This epoch's loss is 0.828948\n","Training epoch 430\n","\n","This epoch's loss is 0.828538\n","Training epoch 431\n","\n","This epoch's loss is 0.828129\n","Training epoch 432\n","\n","This epoch's loss is 0.827721\n","Training epoch 433\n","\n","This epoch's loss is 0.827314\n","Training epoch 434\n","\n","This epoch's loss is 0.826908\n","Training epoch 435\n","\n","This epoch's loss is 0.826503\n","Training epoch 436\n","\n","This epoch's loss is 0.826099\n","Training epoch 437\n","\n","This epoch's loss is 0.825696\n","Training epoch 438\n","\n","This epoch's loss is 0.825294\n","Training epoch 439\n","\n","This epoch's loss is 0.824892\n","Training epoch 440\n","\n","This epoch's loss is 0.824491\n","Training epoch 441\n","\n","This epoch's loss is 0.824091\n","Training epoch 442\n","\n","This epoch's loss is 0.823693\n","Training epoch 443\n","\n","This epoch's loss is 0.823295\n","Training epoch 444\n","\n","This epoch's loss is 0.822899\n","Training epoch 445\n","\n","This epoch's loss is 0.822503\n","Training epoch 446\n","\n","This epoch's loss is 0.822108\n","Training epoch 447\n","\n","This epoch's loss is 0.821715\n","Training epoch 448\n","\n","This epoch's loss is 0.821322\n","Training epoch 449\n","\n","This epoch's loss is 0.820930\n","Training epoch 450\n","\n","This epoch's loss is 0.820539\n","Training epoch 451\n","\n","This epoch's loss is 0.820149\n","Training epoch 452\n","\n","This epoch's loss is 0.819760\n","Training epoch 453\n","\n","This epoch's loss is 0.819372\n","Training epoch 454\n","\n","This epoch's loss is 0.818984\n","Training epoch 455\n","\n","This epoch's loss is 0.818598\n","Training epoch 456\n","\n","This epoch's loss is 0.818212\n","Training epoch 457\n","\n","This epoch's loss is 0.817828\n","Training epoch 458\n","\n","This epoch's loss is 0.817444\n","Training epoch 459\n","\n","This epoch's loss is 0.817061\n","Training epoch 460\n","\n","This epoch's loss is 0.816678\n","Training epoch 461\n","\n","This epoch's loss is 0.816297\n","Training epoch 462\n","\n","This epoch's loss is 0.815917\n","Training epoch 463\n","\n","This epoch's loss is 0.815537\n","Training epoch 464\n","\n","This epoch's loss is 0.815159\n","Training epoch 465\n","\n","This epoch's loss is 0.814781\n","Training epoch 466\n","\n","This epoch's loss is 0.814404\n","Training epoch 467\n","\n","This epoch's loss is 0.814028\n","Training epoch 468\n","\n","This epoch's loss is 0.813652\n","Training epoch 469\n","\n","This epoch's loss is 0.813278\n","Training epoch 470\n","\n","This epoch's loss is 0.812904\n","Training epoch 471\n","\n","This epoch's loss is 0.812532\n","Training epoch 472\n","\n","This epoch's loss is 0.812160\n","Training epoch 473\n","\n","This epoch's loss is 0.811789\n","Training epoch 474\n","\n","This epoch's loss is 0.811419\n","Training epoch 475\n","\n","This epoch's loss is 0.811051\n","Training epoch 476\n","\n","This epoch's loss is 0.810683\n","Training epoch 477\n","\n","This epoch's loss is 0.810315\n","Training epoch 478\n","\n","This epoch's loss is 0.809949\n","Training epoch 479\n","\n","This epoch's loss is 0.809584\n","Training epoch 480\n","\n","This epoch's loss is 0.809219\n","Training epoch 481\n","\n","This epoch's loss is 0.808855\n","Training epoch 482\n","\n","This epoch's loss is 0.808493\n","Training epoch 483\n","\n","This epoch's loss is 0.808131\n","Training epoch 484\n","\n","This epoch's loss is 0.807770\n","Training epoch 485\n","\n","This epoch's loss is 0.807410\n","Training epoch 486\n","\n","This epoch's loss is 0.807049\n","Training epoch 487\n","\n","This epoch's loss is 0.806689\n","Training epoch 488\n","\n","This epoch's loss is 0.806330\n","Training epoch 489\n","\n","This epoch's loss is 0.805972\n","Training epoch 490\n","\n","This epoch's loss is 0.805615\n","Training epoch 491\n","\n","This epoch's loss is 0.805258\n","Training epoch 492\n","\n","This epoch's loss is 0.804903\n","Training epoch 493\n","\n","This epoch's loss is 0.804548\n","Training epoch 494\n","\n","This epoch's loss is 0.804194\n","Training epoch 495\n","\n","This epoch's loss is 0.803841\n","Training epoch 496\n","\n","This epoch's loss is 0.803488\n","Training epoch 497\n","\n","This epoch's loss is 0.803136\n","Training epoch 498\n","\n","This epoch's loss is 0.802785\n","Training epoch 499\n","\n","This epoch's loss is 0.802435\n","Training Complete\n","Training Time: 18.6198 seconds\n","Inference Time: 0.0144 seconds\n","MSE: 0.8454\n","MAPE: 42.0951%\n","\n","============================================================\n","BENCHMARKING SCIKIT-LEARN MLP (SGD)\n","============================================================\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","Training Time: 24.4736 seconds\n","Inference Time: 0.0007 seconds\n","MSE: 0.3349\n","MAPE: 22.6763%\n","\n","===============================================================================================\n","BENCHMARK SUMMARY TABLE\n","===============================================================================================\n","Model                     Train (s)       Infer (s)       MSE             MAPE (%)        Total (s)      \n","-----------------------------------------------------------------------------------------------\n","Custom MLP                18.6198         0.0144          0.8454          42.0951         18.6341        \n","Scikit-Learn MLP          24.4736         0.0007          0.3349          22.6763         24.4743        \n","-----------------------------------------------------------------------------------------------\n","\n","Speedup Factors (relative to Custom MLP):\n","-----------------------------------------------------------------------------------------------\n","Custom MLP                1.00x\n","Scikit-Learn MLP          0.76x\n","===============================================================================================\n","Figure(1400x1000)\n","Figure(1000x600)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736806842,"user_tz":-660,"elapsed":920,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"71d1d35d-c400-4c89-c1a2-c69af98a8c16","id":"uwUCkHPNfrkn"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MLP_from_scratch'...\n","remote: Enumerating objects: 523, done.\u001b[K\n","remote: Counting objects: 100% (523/523), done.\u001b[K\n","remote: Compressing objects: 100% (337/337), done.\u001b[K\n","remote: Total 523 (delta 241), reused 448 (delta 166), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (523/523), 2.38 MiB | 14.66 MiB/s, done.\n","Resolving deltas: 100% (241/241), done.\n"]}],"source":["!git clone https://github.com/toms55/MLP_from_scratch.git"]},{"cell_type":"code","source":["!apt-get update"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736814592,"user_tz":-660,"elapsed":7746,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"4de48119-b21f-4a3d-87f6-3707b0ccfdab","id":"LafCyYOqfrkp"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Connecting to security.ubuntu.com (185.125.190.39)] [Connecting to cloud.r-\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:3 https://cli.github.com/packages stable InRelease\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,065 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,738 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,580 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,808 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,322 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n","Fetched 20.0 MB in 5s (3,837 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}]},{"cell_type":"code","source":["!apt-get install -y gcc cmake gdb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736826339,"user_tz":-660,"elapsed":11740,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"e7ac42b1-816b-4d70-f047-9040df03fcb1","id":"3aP3WtQEfrkp"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","gcc is already the newest version (4:11.2.0-1ubuntu1).\n","gcc set to manually installed.\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","The following additional packages will be installed:\n","  libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n","  libsource-highlight-common libsource-highlight4v5\n","Suggested packages:\n","  gdb-doc gdbserver\n","The following NEW packages will be installed:\n","  gdb libbabeltrace1 libc6-dbg libdebuginfod-common libdebuginfod1 libipt2\n","  libsource-highlight-common libsource-highlight4v5\n","0 upgraded, 8 newly installed, 0 to remove and 40 not upgraded.\n","Need to get 18.3 MB of archives.\n","After this operation, 32.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod-common all 0.186-1ubuntu0.1 [7,996 B]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdebuginfod1 amd64 0.186-1ubuntu0.1 [12.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04.2 [3,920 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.11 [13.9 MB]\n","Fetched 18.3 MB in 1s (31.2 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package libdebuginfod-common.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../0-libdebuginfod-common_0.186-1ubuntu0.1_all.deb ...\n","Unpacking libdebuginfod-common (0.186-1ubuntu0.1) ...\n","Selecting previously unselected package libbabeltrace1:amd64.\n","Preparing to unpack .../1-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n","Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Selecting previously unselected package libdebuginfod1:amd64.\n","Preparing to unpack .../2-libdebuginfod1_0.186-1ubuntu0.1_amd64.deb ...\n","Unpacking libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n","Selecting previously unselected package libipt2.\n","Preparing to unpack .../3-libipt2_2.0.5-1_amd64.deb ...\n","Unpacking libipt2 (2.0.5-1) ...\n","Selecting previously unselected package libsource-highlight-common.\n","Preparing to unpack .../4-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n","Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n","Selecting previously unselected package libsource-highlight4v5.\n","Preparing to unpack .../5-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n","Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Selecting previously unselected package gdb.\n","Preparing to unpack .../6-gdb_12.1-0ubuntu1~22.04.2_amd64.deb ...\n","Unpacking gdb (12.1-0ubuntu1~22.04.2) ...\n","Selecting previously unselected package libc6-dbg:amd64.\n","Preparing to unpack .../7-libc6-dbg_2.35-0ubuntu3.11_amd64.deb ...\n","Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.11) ...\n","Setting up libdebuginfod-common (0.186-1ubuntu0.1) ...\n","\n","Creating config file /etc/profile.d/debuginfod.sh with new version\n","\n","Creating config file /etc/profile.d/debuginfod.csh with new version\n","Setting up libdebuginfod1:amd64 (0.186-1ubuntu0.1) ...\n","Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n","Setting up libc6-dbg:amd64 (2.35-0ubuntu3.11) ...\n","Setting up libipt2 (2.0.5-1) ...\n","Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Setting up gdb (12.1-0ubuntu1~22.04.2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n"]}]},{"cell_type":"code","source":["!pip install numpy pandas scipy matplotlib scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736834096,"user_tz":-660,"elapsed":7749,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"f409edef-b035-48fe-e588-e302f12ce661","id":"x7zg446-frkq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"code","source":["%cd /content/MLP_from_scratch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736834118,"user_tz":-660,"elapsed":8,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"e657a041-1a90-407b-bb9d-5e1a7c44b406","id":"ESZu72ihfrkq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MLP_from_scratch\n"]}]},{"cell_type":"markdown","source":["Compile the C Code"],"metadata":{"id":"LGmHIYp_frkr"}},{"cell_type":"code","source":["!make clean\n","!make all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736835143,"user_tz":-660,"elapsed":1011,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"d4afe506-e38c-454b-9f44-c83fb0d7b657","id":"AImSRW0ufrkr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm -rf build c_src/src/*.o\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/activation.o c_src/src/activation.c\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/loss.o c_src/src/loss.c\n","gcc -O2 -fPIC -Wall -Wextra -g -I./c_src/include   -c -o c_src/src/matrix.o c_src/src/matrix.c\n","mkdir -p build\n","gcc -shared -lm -o build/libmlp.so c_src/src/activation.o c_src/src/loss.o c_src/src/matrix.o\n"]}]},{"cell_type":"code","source":["!python3 python/run.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759736886847,"user_tz":-660,"elapsed":51689,"user":{"displayName":"Thomas Storey","userId":"04032900247195128428"}},"outputId":"bc46aa6d-06a6-4979-b5d3-d4983b21d155","id":"tztOoh9-frkr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","MLP IMPLEMENTATION BENCHMARK\n","================================================================================\n","\n","Loading California Housing Dataset...\n","Scaling features...\n","\n","Dataset Info:\n","Training samples: 18576\n","Test samples: 2064\n","Features: 8\n","Epochs: 500\n","\n","============================================================\n","BENCHMARKING CUSTOM MLP\n","============================================================\n","Training epoch 0\n","\n","This epoch's loss is 2.868645\n","Training epoch 1\n","\n","This epoch's loss is 2.790456\n","Training epoch 2\n","\n","This epoch's loss is 2.718115\n","Training epoch 3\n","\n","This epoch's loss is 2.651047\n","Training epoch 4\n","\n","This epoch's loss is 2.588733\n","Training epoch 5\n","\n","This epoch's loss is 2.530639\n","Training epoch 6\n","\n","This epoch's loss is 2.476347\n","Training epoch 7\n","\n","This epoch's loss is 2.425517\n","Training epoch 8\n","\n","This epoch's loss is 2.377834\n","Training epoch 9\n","\n","This epoch's loss is 2.332970\n","Training epoch 10\n","\n","This epoch's loss is 2.290709\n","Training epoch 11\n","\n","This epoch's loss is 2.250804\n","Training epoch 12\n","\n","This epoch's loss is 2.213039\n","Training epoch 13\n","\n","This epoch's loss is 2.177259\n","Training epoch 14\n","\n","This epoch's loss is 2.143223\n","Training epoch 15\n","\n","This epoch's loss is 2.110577\n","Training epoch 16\n","\n","This epoch's loss is 2.079401\n","Training epoch 17\n","\n","This epoch's loss is 2.049602\n","Training epoch 18\n","\n","This epoch's loss is 2.021106\n","Training epoch 19\n","\n","This epoch's loss is 1.993807\n","Training epoch 20\n","\n","This epoch's loss is 1.967603\n","Training epoch 21\n","\n","This epoch's loss is 1.942411\n","Training epoch 22\n","\n","This epoch's loss is 1.918154\n","Training epoch 23\n","\n","This epoch's loss is 1.894769\n","Training epoch 24\n","\n","This epoch's loss is 1.872188\n","Training epoch 25\n","\n","This epoch's loss is 1.850345\n","Training epoch 26\n","\n","This epoch's loss is 1.829176\n","Training epoch 27\n","\n","This epoch's loss is 1.808672\n","Training epoch 28\n","\n","This epoch's loss is 1.788786\n","Training epoch 29\n","\n","This epoch's loss is 1.769488\n","Training epoch 30\n","\n","This epoch's loss is 1.750740\n","Training epoch 31\n","\n","This epoch's loss is 1.732530\n","Training epoch 32\n","\n","This epoch's loss is 1.714823\n","Training epoch 33\n","\n","This epoch's loss is 1.697600\n","Training epoch 34\n","\n","This epoch's loss is 1.680837\n","Training epoch 35\n","\n","This epoch's loss is 1.664513\n","Training epoch 36\n","\n","This epoch's loss is 1.648610\n","Training epoch 37\n","\n","This epoch's loss is 1.633122\n","Training epoch 38\n","\n","This epoch's loss is 1.618033\n","Training epoch 39\n","\n","This epoch's loss is 1.603312\n","Training epoch 40\n","\n","This epoch's loss is 1.588941\n","Training epoch 41\n","\n","This epoch's loss is 1.574924\n","Training epoch 42\n","\n","This epoch's loss is 1.561243\n","Training epoch 43\n","\n","This epoch's loss is 1.547889\n","Training epoch 44\n","\n","This epoch's loss is 1.534862\n","Training epoch 45\n","\n","This epoch's loss is 1.522152\n","Training epoch 46\n","\n","This epoch's loss is 1.509739\n","Training epoch 47\n","\n","This epoch's loss is 1.497613\n","Training epoch 48\n","\n","This epoch's loss is 1.485766\n","Training epoch 49\n","\n","This epoch's loss is 1.474190\n","Training epoch 50\n","\n","This epoch's loss is 1.462875\n","Training epoch 51\n","\n","This epoch's loss is 1.451833\n","Training epoch 52\n","\n","This epoch's loss is 1.441038\n","Training epoch 53\n","\n","This epoch's loss is 1.430487\n","Training epoch 54\n","\n","This epoch's loss is 1.420188\n","Training epoch 55\n","\n","This epoch's loss is 1.410124\n","Training epoch 56\n","\n","This epoch's loss is 1.400291\n","Training epoch 57\n","\n","This epoch's loss is 1.390679\n","Training epoch 58\n","\n","This epoch's loss is 1.381274\n","Training epoch 59\n","\n","This epoch's loss is 1.372065\n","Training epoch 60\n","\n","This epoch's loss is 1.363051\n","Training epoch 61\n","\n","This epoch's loss is 1.354232\n","Training epoch 62\n","\n","This epoch's loss is 1.345593\n","Training epoch 63\n","\n","This epoch's loss is 1.337144\n","Training epoch 64\n","\n","This epoch's loss is 1.328873\n","Training epoch 65\n","\n","This epoch's loss is 1.320792\n","Training epoch 66\n","\n","This epoch's loss is 1.312880\n","Training epoch 67\n","\n","This epoch's loss is 1.305137\n","Training epoch 68\n","\n","This epoch's loss is 1.297565\n","Training epoch 69\n","\n","This epoch's loss is 1.290189\n","Training epoch 70\n","\n","This epoch's loss is 1.282984\n","Training epoch 71\n","\n","This epoch's loss is 1.275937\n","Training epoch 72\n","\n","This epoch's loss is 1.269063\n","Training epoch 73\n","\n","This epoch's loss is 1.262358\n","Training epoch 74\n","\n","This epoch's loss is 1.255805\n","Training epoch 75\n","\n","This epoch's loss is 1.249415\n","Training epoch 76\n","\n","This epoch's loss is 1.243173\n","Training epoch 77\n","\n","This epoch's loss is 1.237094\n","Training epoch 78\n","\n","This epoch's loss is 1.231259\n","Training epoch 79\n","\n","This epoch's loss is 1.225578\n","Training epoch 80\n","\n","This epoch's loss is 1.220022\n","Training epoch 81\n","\n","This epoch's loss is 1.214584\n","Training epoch 82\n","\n","This epoch's loss is 1.209387\n","Training epoch 83\n","\n","This epoch's loss is 1.204591\n","Training epoch 84\n","\n","This epoch's loss is 1.199874\n","Training epoch 85\n","\n","This epoch's loss is 1.195234\n","Training epoch 86\n","\n","This epoch's loss is 1.190668\n","Training epoch 87\n","\n","This epoch's loss is 1.186229\n","Training epoch 88\n","\n","This epoch's loss is 1.181920\n","Training epoch 89\n","\n","This epoch's loss is 1.177684\n","Training epoch 90\n","\n","This epoch's loss is 1.173527\n","Training epoch 91\n","\n","This epoch's loss is 1.169460\n","Training epoch 92\n","\n","This epoch's loss is 1.165468\n","Training epoch 93\n","\n","This epoch's loss is 1.161549\n","Training epoch 94\n","\n","This epoch's loss is 1.157694\n","Training epoch 95\n","\n","This epoch's loss is 1.153936\n","Training epoch 96\n","\n","This epoch's loss is 1.150251\n","Training epoch 97\n","\n","This epoch's loss is 1.146644\n","Training epoch 98\n","\n","This epoch's loss is 1.143094\n","Training epoch 99\n","\n","This epoch's loss is 1.139605\n","Training epoch 100\n","\n","This epoch's loss is 1.136177\n","Training epoch 101\n","\n","This epoch's loss is 1.132808\n","Training epoch 102\n","\n","This epoch's loss is 1.129494\n","Training epoch 103\n","\n","This epoch's loss is 1.126242\n","Training epoch 104\n","\n","This epoch's loss is 1.123072\n","Training epoch 105\n","\n","This epoch's loss is 1.119956\n","Training epoch 106\n","\n","This epoch's loss is 1.116922\n","Training epoch 107\n","\n","This epoch's loss is 1.114011\n","Training epoch 108\n","\n","This epoch's loss is 1.111146\n","Training epoch 109\n","\n","This epoch's loss is 1.108327\n","Training epoch 110\n","\n","This epoch's loss is 1.105549\n","Training epoch 111\n","\n","This epoch's loss is 1.102815\n","Training epoch 112\n","\n","This epoch's loss is 1.100126\n","Training epoch 113\n","\n","This epoch's loss is 1.097476\n","Training epoch 114\n","\n","This epoch's loss is 1.094870\n","Training epoch 115\n","\n","This epoch's loss is 1.092303\n","Training epoch 116\n","\n","This epoch's loss is 1.089777\n","Training epoch 117\n","\n","This epoch's loss is 1.087298\n","Training epoch 118\n","\n","This epoch's loss is 1.084856\n","Training epoch 119\n","\n","This epoch's loss is 1.082450\n","Training epoch 120\n","\n","This epoch's loss is 1.080080\n","Training epoch 121\n","\n","This epoch's loss is 1.077748\n","Training epoch 122\n","\n","This epoch's loss is 1.075455\n","Training epoch 123\n","\n","This epoch's loss is 1.073203\n","Training epoch 124\n","\n","This epoch's loss is 1.070988\n","Training epoch 125\n","\n","This epoch's loss is 1.068813\n","Training epoch 126\n","\n","This epoch's loss is 1.066674\n","Training epoch 127\n","\n","This epoch's loss is 1.064566\n","Training epoch 128\n","\n","This epoch's loss is 1.062487\n","Training epoch 129\n","\n","This epoch's loss is 1.060438\n","Training epoch 130\n","\n","This epoch's loss is 1.058418\n","Training epoch 131\n","\n","This epoch's loss is 1.056426\n","Training epoch 132\n","\n","This epoch's loss is 1.054461\n","Training epoch 133\n","\n","This epoch's loss is 1.052522\n","Training epoch 134\n","\n","This epoch's loss is 1.050609\n","Training epoch 135\n","\n","This epoch's loss is 1.048723\n","Training epoch 136\n","\n","This epoch's loss is 1.046867\n","Training epoch 137\n","\n","This epoch's loss is 1.045044\n","Training epoch 138\n","\n","This epoch's loss is 1.043245\n","Training epoch 139\n","\n","This epoch's loss is 1.041469\n","Training epoch 140\n","\n","This epoch's loss is 1.039717\n","Training epoch 141\n","\n","This epoch's loss is 1.037987\n","Training epoch 142\n","\n","This epoch's loss is 1.036278\n","Training epoch 143\n","\n","This epoch's loss is 1.034591\n","Training epoch 144\n","\n","This epoch's loss is 1.032924\n","Training epoch 145\n","\n","This epoch's loss is 1.031279\n","Training epoch 146\n","\n","This epoch's loss is 1.029655\n","Training epoch 147\n","\n","This epoch's loss is 1.028052\n","Training epoch 148\n","\n","This epoch's loss is 1.026466\n","Training epoch 149\n","\n","This epoch's loss is 1.024901\n","Training epoch 150\n","\n","This epoch's loss is 1.023354\n","Training epoch 151\n","\n","This epoch's loss is 1.021826\n","Training epoch 152\n","\n","This epoch's loss is 1.020316\n","Training epoch 153\n","\n","This epoch's loss is 1.018824\n","Training epoch 154\n","\n","This epoch's loss is 1.017351\n","Training epoch 155\n","\n","This epoch's loss is 1.015893\n","Training epoch 156\n","\n","This epoch's loss is 1.014452\n","Training epoch 157\n","\n","This epoch's loss is 1.013028\n","Training epoch 158\n","\n","This epoch's loss is 1.011621\n","Training epoch 159\n","\n","This epoch's loss is 1.010230\n","Training epoch 160\n","\n","This epoch's loss is 1.008856\n","Training epoch 161\n","\n","This epoch's loss is 1.007497\n","Training epoch 162\n","\n","This epoch's loss is 1.006154\n","Training epoch 163\n","\n","This epoch's loss is 1.004826\n","Training epoch 164\n","\n","This epoch's loss is 1.003513\n","Training epoch 165\n","\n","This epoch's loss is 1.002214\n","Training epoch 166\n","\n","This epoch's loss is 1.000928\n","Training epoch 167\n","\n","This epoch's loss is 0.999657\n","Training epoch 168\n","\n","This epoch's loss is 0.998399\n","Training epoch 169\n","\n","This epoch's loss is 0.997155\n","Training epoch 170\n","\n","This epoch's loss is 0.995922\n","Training epoch 171\n","\n","This epoch's loss is 0.994701\n","Training epoch 172\n","\n","This epoch's loss is 0.993493\n","Training epoch 173\n","\n","This epoch's loss is 0.992296\n","Training epoch 174\n","\n","This epoch's loss is 0.991109\n","Training epoch 175\n","\n","This epoch's loss is 0.989934\n","Training epoch 176\n","\n","This epoch's loss is 0.988769\n","Training epoch 177\n","\n","This epoch's loss is 0.987615\n","Training epoch 178\n","\n","This epoch's loss is 0.986471\n","Training epoch 179\n","\n","This epoch's loss is 0.985337\n","Training epoch 180\n","\n","This epoch's loss is 0.984213\n","Training epoch 181\n","\n","This epoch's loss is 0.983099\n","Training epoch 182\n","\n","This epoch's loss is 0.981994\n","Training epoch 183\n","\n","This epoch's loss is 0.980899\n","Training epoch 184\n","\n","This epoch's loss is 0.979813\n","Training epoch 185\n","\n","This epoch's loss is 0.978741\n","Training epoch 186\n","\n","This epoch's loss is 0.977681\n","Training epoch 187\n","\n","This epoch's loss is 0.976630\n","Training epoch 188\n","\n","This epoch's loss is 0.975588\n","Training epoch 189\n","\n","This epoch's loss is 0.974555\n","Training epoch 190\n","\n","This epoch's loss is 0.973531\n","Training epoch 191\n","\n","This epoch's loss is 0.972515\n","Training epoch 192\n","\n","This epoch's loss is 0.971507\n","Training epoch 193\n","\n","This epoch's loss is 0.970507\n","Training epoch 194\n","\n","This epoch's loss is 0.969514\n","Training epoch 195\n","\n","This epoch's loss is 0.968529\n","Training epoch 196\n","\n","This epoch's loss is 0.967551\n","Training epoch 197\n","\n","This epoch's loss is 0.966581\n","Training epoch 198\n","\n","This epoch's loss is 0.965618\n","Training epoch 199\n","\n","This epoch's loss is 0.964664\n","Training epoch 200\n","\n","This epoch's loss is 0.963717\n","Training epoch 201\n","\n","This epoch's loss is 0.962777\n","Training epoch 202\n","\n","This epoch's loss is 0.961842\n","Training epoch 203\n","\n","This epoch's loss is 0.960915\n","Training epoch 204\n","\n","This epoch's loss is 0.959993\n","Training epoch 205\n","\n","This epoch's loss is 0.959078\n","Training epoch 206\n","\n","This epoch's loss is 0.958169\n","Training epoch 207\n","\n","This epoch's loss is 0.957265\n","Training epoch 208\n","\n","This epoch's loss is 0.956368\n","Training epoch 209\n","\n","This epoch's loss is 0.955477\n","Training epoch 210\n","\n","This epoch's loss is 0.954592\n","Training epoch 211\n","\n","This epoch's loss is 0.953713\n","Training epoch 212\n","\n","This epoch's loss is 0.952840\n","Training epoch 213\n","\n","This epoch's loss is 0.951972\n","Training epoch 214\n","\n","This epoch's loss is 0.951111\n","Training epoch 215\n","\n","This epoch's loss is 0.950254\n","Training epoch 216\n","\n","This epoch's loss is 0.949404\n","Training epoch 217\n","\n","This epoch's loss is 0.948559\n","Training epoch 218\n","\n","This epoch's loss is 0.947720\n","Training epoch 219\n","\n","This epoch's loss is 0.946885\n","Training epoch 220\n","\n","This epoch's loss is 0.946055\n","Training epoch 221\n","\n","This epoch's loss is 0.945230\n","Training epoch 222\n","\n","This epoch's loss is 0.944410\n","Training epoch 223\n","\n","This epoch's loss is 0.943595\n","Training epoch 224\n","\n","This epoch's loss is 0.942784\n","Training epoch 225\n","\n","This epoch's loss is 0.941978\n","Training epoch 226\n","\n","This epoch's loss is 0.941176\n","Training epoch 227\n","\n","This epoch's loss is 0.940379\n","Training epoch 228\n","\n","This epoch's loss is 0.939586\n","Training epoch 229\n","\n","This epoch's loss is 0.938797\n","Training epoch 230\n","\n","This epoch's loss is 0.938014\n","Training epoch 231\n","\n","This epoch's loss is 0.937234\n","Training epoch 232\n","\n","This epoch's loss is 0.936460\n","Training epoch 233\n","\n","This epoch's loss is 0.935689\n","Training epoch 234\n","\n","This epoch's loss is 0.934923\n","Training epoch 235\n","\n","This epoch's loss is 0.934161\n","Training epoch 236\n","\n","This epoch's loss is 0.933402\n","Training epoch 237\n","\n","This epoch's loss is 0.932647\n","Training epoch 238\n","\n","This epoch's loss is 0.931896\n","Training epoch 239\n","\n","This epoch's loss is 0.931147\n","Training epoch 240\n","\n","This epoch's loss is 0.930402\n","Training epoch 241\n","\n","This epoch's loss is 0.929662\n","Training epoch 242\n","\n","This epoch's loss is 0.928925\n","Training epoch 243\n","\n","This epoch's loss is 0.928190\n","Training epoch 244\n","\n","This epoch's loss is 0.927460\n","Training epoch 245\n","\n","This epoch's loss is 0.926733\n","Training epoch 246\n","\n","This epoch's loss is 0.926010\n","Training epoch 247\n","\n","This epoch's loss is 0.925291\n","Training epoch 248\n","\n","This epoch's loss is 0.924575\n","Training epoch 249\n","\n","This epoch's loss is 0.923862\n","Training epoch 250\n","\n","This epoch's loss is 0.923153\n","Training epoch 251\n","\n","This epoch's loss is 0.922447\n","Training epoch 252\n","\n","This epoch's loss is 0.921744\n","Training epoch 253\n","\n","This epoch's loss is 0.921043\n","Training epoch 254\n","\n","This epoch's loss is 0.920347\n","Training epoch 255\n","\n","This epoch's loss is 0.919653\n","Training epoch 256\n","\n","This epoch's loss is 0.918964\n","Training epoch 257\n","\n","This epoch's loss is 0.918278\n","Training epoch 258\n","\n","This epoch's loss is 0.917595\n","Training epoch 259\n","\n","This epoch's loss is 0.916915\n","Training epoch 260\n","\n","This epoch's loss is 0.916238\n","Training epoch 261\n","\n","This epoch's loss is 0.915564\n","Training epoch 262\n","\n","This epoch's loss is 0.914892\n","Training epoch 263\n","\n","This epoch's loss is 0.914223\n","Training epoch 264\n","\n","This epoch's loss is 0.913556\n","Training epoch 265\n","\n","This epoch's loss is 0.912893\n","Training epoch 266\n","\n","This epoch's loss is 0.912233\n","Training epoch 267\n","\n","This epoch's loss is 0.911575\n","Training epoch 268\n","\n","This epoch's loss is 0.910920\n","Training epoch 269\n","\n","This epoch's loss is 0.910268\n","Training epoch 270\n","\n","This epoch's loss is 0.909619\n","Training epoch 271\n","\n","This epoch's loss is 0.908972\n","Training epoch 272\n","\n","This epoch's loss is 0.908329\n","Training epoch 273\n","\n","This epoch's loss is 0.907688\n","Training epoch 274\n","\n","This epoch's loss is 0.907050\n","Training epoch 275\n","\n","This epoch's loss is 0.906414\n","Training epoch 276\n","\n","This epoch's loss is 0.905780\n","Training epoch 277\n","\n","This epoch's loss is 0.905150\n","Training epoch 278\n","\n","This epoch's loss is 0.904521\n","Training epoch 279\n","\n","This epoch's loss is 0.903894\n","Training epoch 280\n","\n","This epoch's loss is 0.903269\n","Training epoch 281\n","\n","This epoch's loss is 0.902647\n","Training epoch 282\n","\n","This epoch's loss is 0.902027\n","Training epoch 283\n","\n","This epoch's loss is 0.901410\n","Training epoch 284\n","\n","This epoch's loss is 0.900794\n","Training epoch 285\n","\n","This epoch's loss is 0.900181\n","Training epoch 286\n","\n","This epoch's loss is 0.899570\n","Training epoch 287\n","\n","This epoch's loss is 0.898962\n","Training epoch 288\n","\n","This epoch's loss is 0.898355\n","Training epoch 289\n","\n","This epoch's loss is 0.897750\n","Training epoch 290\n","\n","This epoch's loss is 0.897147\n","Training epoch 291\n","\n","This epoch's loss is 0.896546\n","Training epoch 292\n","\n","This epoch's loss is 0.895947\n","Training epoch 293\n","\n","This epoch's loss is 0.895350\n","Training epoch 294\n","\n","This epoch's loss is 0.894756\n","Training epoch 295\n","\n","This epoch's loss is 0.894164\n","Training epoch 296\n","\n","This epoch's loss is 0.893574\n","Training epoch 297\n","\n","This epoch's loss is 0.892985\n","Training epoch 298\n","\n","This epoch's loss is 0.892398\n","Training epoch 299\n","\n","This epoch's loss is 0.891814\n","Training epoch 300\n","\n","This epoch's loss is 0.891232\n","Training epoch 301\n","\n","This epoch's loss is 0.890652\n","Training epoch 302\n","\n","This epoch's loss is 0.890074\n","Training epoch 303\n","\n","This epoch's loss is 0.889499\n","Training epoch 304\n","\n","This epoch's loss is 0.888925\n","Training epoch 305\n","\n","This epoch's loss is 0.888353\n","Training epoch 306\n","\n","This epoch's loss is 0.887782\n","Training epoch 307\n","\n","This epoch's loss is 0.887214\n","Training epoch 308\n","\n","This epoch's loss is 0.886648\n","Training epoch 309\n","\n","This epoch's loss is 0.886083\n","Training epoch 310\n","\n","This epoch's loss is 0.885520\n","Training epoch 311\n","\n","This epoch's loss is 0.884959\n","Training epoch 312\n","\n","This epoch's loss is 0.884401\n","Training epoch 313\n","\n","This epoch's loss is 0.883844\n","Training epoch 314\n","\n","This epoch's loss is 0.883288\n","Training epoch 315\n","\n","This epoch's loss is 0.882735\n","Training epoch 316\n","\n","This epoch's loss is 0.882184\n","Training epoch 317\n","\n","This epoch's loss is 0.881634\n","Training epoch 318\n","\n","This epoch's loss is 0.881086\n","Training epoch 319\n","\n","This epoch's loss is 0.880541\n","Training epoch 320\n","\n","This epoch's loss is 0.879996\n","Training epoch 321\n","\n","This epoch's loss is 0.879454\n","Training epoch 322\n","\n","This epoch's loss is 0.878914\n","Training epoch 323\n","\n","This epoch's loss is 0.878375\n","Training epoch 324\n","\n","This epoch's loss is 0.877838\n","Training epoch 325\n","\n","This epoch's loss is 0.877302\n","Training epoch 326\n","\n","This epoch's loss is 0.876768\n","Training epoch 327\n","\n","This epoch's loss is 0.876235\n","Training epoch 328\n","\n","This epoch's loss is 0.875704\n","Training epoch 329\n","\n","This epoch's loss is 0.875174\n","Training epoch 330\n","\n","This epoch's loss is 0.874646\n","Training epoch 331\n","\n","This epoch's loss is 0.874120\n","Training epoch 332\n","\n","This epoch's loss is 0.873595\n","Training epoch 333\n","\n","This epoch's loss is 0.873072\n","Training epoch 334\n","\n","This epoch's loss is 0.872551\n","Training epoch 335\n","\n","This epoch's loss is 0.872031\n","Training epoch 336\n","\n","This epoch's loss is 0.871512\n","Training epoch 337\n","\n","This epoch's loss is 0.870995\n","Training epoch 338\n","\n","This epoch's loss is 0.870480\n","Training epoch 339\n","\n","This epoch's loss is 0.869966\n","Training epoch 340\n","\n","This epoch's loss is 0.869453\n","Training epoch 341\n","\n","This epoch's loss is 0.868942\n","Training epoch 342\n","\n","This epoch's loss is 0.868433\n","Training epoch 343\n","\n","This epoch's loss is 0.867925\n","Training epoch 344\n","\n","This epoch's loss is 0.867419\n","Training epoch 345\n","\n","This epoch's loss is 0.866914\n","Training epoch 346\n","\n","This epoch's loss is 0.866410\n","Training epoch 347\n","\n","This epoch's loss is 0.865908\n","Training epoch 348\n","\n","This epoch's loss is 0.865407\n","Training epoch 349\n","\n","This epoch's loss is 0.864908\n","Training epoch 350\n","\n","This epoch's loss is 0.864409\n","Training epoch 351\n","\n","This epoch's loss is 0.863912\n","Training epoch 352\n","\n","This epoch's loss is 0.863417\n","Training epoch 353\n","\n","This epoch's loss is 0.862923\n","Training epoch 354\n","\n","This epoch's loss is 0.862431\n","Training epoch 355\n","\n","This epoch's loss is 0.861940\n","Training epoch 356\n","\n","This epoch's loss is 0.861450\n","Training epoch 357\n","\n","This epoch's loss is 0.860962\n","Training epoch 358\n","\n","This epoch's loss is 0.860475\n","Training epoch 359\n","\n","This epoch's loss is 0.859989\n","Training epoch 360\n","\n","This epoch's loss is 0.859505\n","Training epoch 361\n","\n","This epoch's loss is 0.859022\n","Training epoch 362\n","\n","This epoch's loss is 0.858540\n","Training epoch 363\n","\n","This epoch's loss is 0.858060\n","Training epoch 364\n","\n","This epoch's loss is 0.857581\n","Training epoch 365\n","\n","This epoch's loss is 0.857103\n","Training epoch 366\n","\n","This epoch's loss is 0.856627\n","Training epoch 367\n","\n","This epoch's loss is 0.856152\n","Training epoch 368\n","\n","This epoch's loss is 0.855678\n","Training epoch 369\n","\n","This epoch's loss is 0.855206\n","Training epoch 370\n","\n","This epoch's loss is 0.854735\n","Training epoch 371\n","\n","This epoch's loss is 0.854266\n","Training epoch 372\n","\n","This epoch's loss is 0.853798\n","Training epoch 373\n","\n","This epoch's loss is 0.853331\n","Training epoch 374\n","\n","This epoch's loss is 0.852865\n","Training epoch 375\n","\n","This epoch's loss is 0.852400\n","Training epoch 376\n","\n","This epoch's loss is 0.851936\n","Training epoch 377\n","\n","This epoch's loss is 0.851474\n","Training epoch 378\n","\n","This epoch's loss is 0.851014\n","Training epoch 379\n","\n","This epoch's loss is 0.850554\n","Training epoch 380\n","\n","This epoch's loss is 0.850096\n","Training epoch 381\n","\n","This epoch's loss is 0.849638\n","Training epoch 382\n","\n","This epoch's loss is 0.849181\n","Training epoch 383\n","\n","This epoch's loss is 0.848726\n","Training epoch 384\n","\n","This epoch's loss is 0.848273\n","Training epoch 385\n","\n","This epoch's loss is 0.847821\n","Training epoch 386\n","\n","This epoch's loss is 0.847369\n","Training epoch 387\n","\n","This epoch's loss is 0.846919\n","Training epoch 388\n","\n","This epoch's loss is 0.846470\n","Training epoch 389\n","\n","This epoch's loss is 0.846022\n","Training epoch 390\n","\n","This epoch's loss is 0.845575\n","Training epoch 391\n","\n","This epoch's loss is 0.845129\n","Training epoch 392\n","\n","This epoch's loss is 0.844685\n","Training epoch 393\n","\n","This epoch's loss is 0.844241\n","Training epoch 394\n","\n","This epoch's loss is 0.843799\n","Training epoch 395\n","\n","This epoch's loss is 0.843357\n","Training epoch 396\n","\n","This epoch's loss is 0.842917\n","Training epoch 397\n","\n","This epoch's loss is 0.842476\n","Training epoch 398\n","\n","This epoch's loss is 0.842037\n","Training epoch 399\n","\n","This epoch's loss is 0.841600\n","Training epoch 400\n","\n","This epoch's loss is 0.841163\n","Training epoch 401\n","\n","This epoch's loss is 0.840727\n","Training epoch 402\n","\n","This epoch's loss is 0.840293\n","Training epoch 403\n","\n","This epoch's loss is 0.839860\n","Training epoch 404\n","\n","This epoch's loss is 0.839428\n","Training epoch 405\n","\n","This epoch's loss is 0.838997\n","Training epoch 406\n","\n","This epoch's loss is 0.838568\n","Training epoch 407\n","\n","This epoch's loss is 0.838139\n","Training epoch 408\n","\n","This epoch's loss is 0.837712\n","Training epoch 409\n","\n","This epoch's loss is 0.837286\n","Training epoch 410\n","\n","This epoch's loss is 0.836861\n","Training epoch 411\n","\n","This epoch's loss is 0.836437\n","Training epoch 412\n","\n","This epoch's loss is 0.836015\n","Training epoch 413\n","\n","This epoch's loss is 0.835593\n","Training epoch 414\n","\n","This epoch's loss is 0.835173\n","Training epoch 415\n","\n","This epoch's loss is 0.834754\n","Training epoch 416\n","\n","This epoch's loss is 0.834336\n","Training epoch 417\n","\n","This epoch's loss is 0.833919\n","Training epoch 418\n","\n","This epoch's loss is 0.833503\n","Training epoch 419\n","\n","This epoch's loss is 0.833089\n","Training epoch 420\n","\n","This epoch's loss is 0.832675\n","Training epoch 421\n","\n","This epoch's loss is 0.832262\n","Training epoch 422\n","\n","This epoch's loss is 0.831844\n","Training epoch 423\n","\n","This epoch's loss is 0.831427\n","Training epoch 424\n","\n","This epoch's loss is 0.831011\n","Training epoch 425\n","\n","This epoch's loss is 0.830596\n","Training epoch 426\n","\n","This epoch's loss is 0.830183\n","Training epoch 427\n","\n","This epoch's loss is 0.829770\n","Training epoch 428\n","\n","This epoch's loss is 0.829358\n","Training epoch 429\n","\n","This epoch's loss is 0.828948\n","Training epoch 430\n","\n","This epoch's loss is 0.828538\n","Training epoch 431\n","\n","This epoch's loss is 0.828129\n","Training epoch 432\n","\n","This epoch's loss is 0.827721\n","Training epoch 433\n","\n","This epoch's loss is 0.827314\n","Training epoch 434\n","\n","This epoch's loss is 0.826908\n","Training epoch 435\n","\n","This epoch's loss is 0.826503\n","Training epoch 436\n","\n","This epoch's loss is 0.826099\n","Training epoch 437\n","\n","This epoch's loss is 0.825696\n","Training epoch 438\n","\n","This epoch's loss is 0.825294\n","Training epoch 439\n","\n","This epoch's loss is 0.824892\n","Training epoch 440\n","\n","This epoch's loss is 0.824491\n","Training epoch 441\n","\n","This epoch's loss is 0.824091\n","Training epoch 442\n","\n","This epoch's loss is 0.823693\n","Training epoch 443\n","\n","This epoch's loss is 0.823295\n","Training epoch 444\n","\n","This epoch's loss is 0.822899\n","Training epoch 445\n","\n","This epoch's loss is 0.822503\n","Training epoch 446\n","\n","This epoch's loss is 0.822108\n","Training epoch 447\n","\n","This epoch's loss is 0.821715\n","Training epoch 448\n","\n","This epoch's loss is 0.821322\n","Training epoch 449\n","\n","This epoch's loss is 0.820930\n","Training epoch 450\n","\n","This epoch's loss is 0.820539\n","Training epoch 451\n","\n","This epoch's loss is 0.820149\n","Training epoch 452\n","\n","This epoch's loss is 0.819760\n","Training epoch 453\n","\n","This epoch's loss is 0.819372\n","Training epoch 454\n","\n","This epoch's loss is 0.818984\n","Training epoch 455\n","\n","This epoch's loss is 0.818598\n","Training epoch 456\n","\n","This epoch's loss is 0.818212\n","Training epoch 457\n","\n","This epoch's loss is 0.817828\n","Training epoch 458\n","\n","This epoch's loss is 0.817444\n","Training epoch 459\n","\n","This epoch's loss is 0.817061\n","Training epoch 460\n","\n","This epoch's loss is 0.816678\n","Training epoch 461\n","\n","This epoch's loss is 0.816297\n","Training epoch 462\n","\n","This epoch's loss is 0.815917\n","Training epoch 463\n","\n","This epoch's loss is 0.815537\n","Training epoch 464\n","\n","This epoch's loss is 0.815159\n","Training epoch 465\n","\n","This epoch's loss is 0.814781\n","Training epoch 466\n","\n","This epoch's loss is 0.814404\n","Training epoch 467\n","\n","This epoch's loss is 0.814028\n","Training epoch 468\n","\n","This epoch's loss is 0.813652\n","Training epoch 469\n","\n","This epoch's loss is 0.813278\n","Training epoch 470\n","\n","This epoch's loss is 0.812904\n","Training epoch 471\n","\n","This epoch's loss is 0.812532\n","Training epoch 472\n","\n","This epoch's loss is 0.812160\n","Training epoch 473\n","\n","This epoch's loss is 0.811789\n","Training epoch 474\n","\n","This epoch's loss is 0.811419\n","Training epoch 475\n","\n","This epoch's loss is 0.811051\n","Training epoch 476\n","\n","This epoch's loss is 0.810683\n","Training epoch 477\n","\n","This epoch's loss is 0.810315\n","Training epoch 478\n","\n","This epoch's loss is 0.809949\n","Training epoch 479\n","\n","This epoch's loss is 0.809584\n","Training epoch 480\n","\n","This epoch's loss is 0.809219\n","Training epoch 481\n","\n","This epoch's loss is 0.808855\n","Training epoch 482\n","\n","This epoch's loss is 0.808493\n","Training epoch 483\n","\n","This epoch's loss is 0.808131\n","Training epoch 484\n","\n","This epoch's loss is 0.807770\n","Training epoch 485\n","\n","This epoch's loss is 0.807410\n","Training epoch 486\n","\n","This epoch's loss is 0.807049\n","Training epoch 487\n","\n","This epoch's loss is 0.806689\n","Training epoch 488\n","\n","This epoch's loss is 0.806330\n","Training epoch 489\n","\n","This epoch's loss is 0.805972\n","Training epoch 490\n","\n","This epoch's loss is 0.805615\n","Training epoch 491\n","\n","This epoch's loss is 0.805258\n","Training epoch 492\n","\n","This epoch's loss is 0.804903\n","Training epoch 493\n","\n","This epoch's loss is 0.804548\n","Training epoch 494\n","\n","This epoch's loss is 0.804194\n","Training epoch 495\n","\n","This epoch's loss is 0.803841\n","Training epoch 496\n","\n","This epoch's loss is 0.803488\n","Training epoch 497\n","\n","This epoch's loss is 0.803136\n","Training epoch 498\n","\n","This epoch's loss is 0.802785\n","Training epoch 499\n","\n","This epoch's loss is 0.802435\n","Training Complete\n","Training Time: 18.6198 seconds\n","Inference Time: 0.0144 seconds\n","MSE: 0.8454\n","MAPE: 42.0951%\n","\n","============================================================\n","BENCHMARKING SCIKIT-LEARN MLP (SGD)\n","============================================================\n","/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","Training Time: 24.4736 seconds\n","Inference Time: 0.0007 seconds\n","MSE: 0.3349\n","MAPE: 22.6763%\n","\n","===============================================================================================\n","BENCHMARK SUMMARY TABLE\n","===============================================================================================\n","Model                     Train (s)       Infer (s)       MSE             MAPE (%)        Total (s)      \n","-----------------------------------------------------------------------------------------------\n","Custom MLP                18.6198         0.0144          0.8454          42.0951         18.6341        \n","Scikit-Learn MLP          24.4736         0.0007          0.3349          22.6763         24.4743        \n","-----------------------------------------------------------------------------------------------\n","\n","Speedup Factors (relative to Custom MLP):\n","-----------------------------------------------------------------------------------------------\n","Custom MLP                1.00x\n","Scikit-Learn MLP          0.76x\n","===============================================================================================\n","Figure(1400x1000)\n","Figure(1000x600)\n"]}]}]}